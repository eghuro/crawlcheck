{"name":"Crawlcheck","tagline":"Extendable web checker","body":"# Crawlcheck\r\n\r\nCrawlcheck is a web crawler invoking plugins on received content. It's intended for verification of websites prior to deployment. The process of verification is customisable by configuration script that allows complex specification which plugins should check particular URIs and content-types. Main engine and plugins are written in Python, there's also possibility to show report in form of website written in Ruby on Rails or generate report in PDF. The report contains discoveries plugins made during the verification.\r\n\r\n### Version\r\n0.02\r\n\r\n### Tech\r\n\r\nCrawlcheck's engine currently runs on Python 2.7 and uses SQLite3 as a database backend. Report website is using Ruby on Rails and Bootstrap.\r\nCrawlcheck uses a number of open source projects to work properly:\r\n* [Yapsy] - plugin framework\r\n* [sqlite3] - data storage\r\n* [pyyaml] - configuration \r\n* [marisa_trie] - Trie implementation\r\n* [py_w3c] - for html validation plugin\r\n* [tinycss] - for css validation plugin\r\n* [beautifulsoup4] - for links finder plugin\r\n* [requests], [urllib3] - for networking\r\n* [enum] - duh\r\n\r\nFollowing gems are needed for report\r\n* rails\r\n* sqlite3\r\n* sass-rails\r\n* uglifier\r\n* coffee-rails\r\n* jquery-rails\r\n* turbolinks\r\n* jbuilder\r\n* sdoc\r\n* will_paginate-bootstrap\r\n* bootstrap-sass\r\n* autoprefixer-rails\r\n\r\n\r\nAnd of course Crawlcheck itself is open source with a [public repository](https://github.com/eghuro/crawlcheck) on GitHub.\r\n\r\n### Installation\r\n\r\n1) Install dependencies\r\n* You need mysql-server, python-2.7, sqlite3 (dev) and ruby installed.\r\n* Following packages needs also to be installed. It can be done through pip (you need python-pip and python-dev):\r\n```sh\r\n$ pip install marisa_trie yapsy py_w3c enum urllib3 requests tinycss beautifulsoup4 pyyaml\r\n```\r\n* For report, rails also needs to be installed\r\n```sh\r\n$ gem install rails\r\n```\r\n2) Install crawlcheck\r\n* Clone and install Crawlcheck as follows: (make sure to prepare configuration file beforehand)\r\n```sh\r\n$ git clone [git-repo-url] crawlcheck\r\n$ cd crawlcheck/src\r\n```\r\n* Install report\r\n```sh\r\n$ cd report\r\n$ bin/bundle install\r\n```\r\n* Install database\r\n\r\n  First sqlite command will create tables, rake command will do initialization needed for ruby, second sqlite call will set up initial values in certain tables and ensures integrity constraints remains unchanged.\r\n```sh\r\n$ sqlite3 <dbfile> < ../checker/mysql_tables.sql\r\n$ DATABASE_URL=\"sqlite3://<dbfile>\" bin/rake db:drop db:create db:schema:load\r\n$ sqlite3 <dbfile> < ../checker/mysql_tables.sql\r\n```\r\n\r\n### Configuration\r\nConfiguration file is a simple YAML file.\r\n```sh\r\n---\r\nversion: 1.01        # configuration format version\r\ndatabase: crawlcheck # sqlite database file\r\n\r\ncontent-types:\r\n -\r\n   \"content-type\": \"text/html\"\r\n   plugins: # plugins to use for given content-type\r\n     - linksFinder\r\n     - htmlValidator\r\n     \r\n -\r\n   \"content-type\": \"text/css\"\r\n   plugins:\r\n     - tinycss\r\n\r\nurls:\r\n-\r\n  url: \"http://mj.ucw.cz/vyuka/\"\r\n  plugins: # which plugins are allowed for given URL\r\n       - linksFinder\r\n       - htmlValidator\r\n       - tinycss\r\n\r\nentryPoints: # where to start\r\n# Note, that once URI get's to the database it's no longer being requested \r\n# (beware of repeated starts, if entry point remains in the database execution won't \r\n# start from this entry point)\r\n - \"http://mj.ucw.cz/vyuka/\"\r\n```\r\n\r\n### Running crawlcheck\r\nAssuming you have gone through set-up and configuration, now run checker:\r\n```sh\r\n$ cd [root]/crawlcheck/src/\r\n$ python checker/ [config.yml]\r\n```\r\nNote: ```[root]/crawlcheck``` is where repository was cloned to, ```[config.xml]``` stands for the configuration file path\r\n\r\n### Running report website\r\nAssuming you have gone through set-up and configuration and checker either finished or is still running (otherwise there are just no data to display), now run report app:\r\n```sh\r\n$ cd [root]/crawlcheck/src/report/\r\n$ DATABASE_URL=\"sqlite3://<dbfile>\" bin/rails server\r\n```\r\nNote: you can specify port by adding ```-p [number]``` and interface by specifying ```-b [ip address]```\r\n\r\n### Generating report to PDF\r\nThere is also a very simple Python script to generate a PDF containing all invalid links and other defects.\r\nTo run the script you need MySQL connector (you already have, since you ran checker) and ``pylatex``.\r\nYou can install pylatex using PIP:\r\n```sh\r\n$ pip install pylatex\r\n```\r\nYou should also have ```pdflatex``` on your system.\r\n\r\nNow run the script as follows:\r\n```sh\r\n$ cd [root]/crawlcheck/src\r\n$ python TexReporter.py <dbfile> <outputfile>\r\n```\r\nFor output file ``.pdf`` is added automatically.\r\n\r\n\r\n### Plugins\r\n\r\nCrawlcheck is currently extended with the following plugins:\r\n\r\n* linksFinder\r\n* py_w3c_htmlValidator\r\n* tinycss_cssValidator\r\n\r\n### How to write a plugin\r\n\r\nGo to ``crawlcheck/src/checker/plugin/``, create ``my_new_plugin.py`` and ``my_new_plugin.yapsy-plugin`` files there.\r\nFill out .yapsy-plugin file:\r\n```sh\r\n[Core]\r\nName = Human readable plugin name\r\nModule = my_new_plugin\r\n\r\n[Documentation]\r\nAuthor = Your Name\r\nVersion = 0.0\r\nDescription = My New Plugin\r\n```\r\n\r\nFor plugin itself you need to implement following:\r\n```sh\r\nfrom yapsy.IPlugin import IPlugin\r\nclass MyPlugin(IPlugin):\r\n\r\n    def setDb(self, DB):\r\n        # record DB somewhere\r\n\r\n    def getId(self):\r\n        \"\"\" The id is used in configuration - in this case <plugin id = \"myPlugin\"/>\r\n        \"\"\"\r\n\r\n        return \"myPlugin\"\r\n\r\n    def check(self, transactionId, content):\r\n        # implement the logic here\r\n```\r\n\r\nSee http://yapsy.sourceforge.net/IPlugin.html and http://yapsy.sourceforge.net/PluginManager.html#plugin-info-file-format for more details.\r\n\r\n### TODOs\r\n\r\n - Improve Tests and Documentation\r\n - Report - manual annotations of findings\r\n - Filters and search in report\r\n - Scrap inline css\r\n - Regular expressions in configuration for plugins (URLs)\r\n\r\nLicense\r\n----\r\n\r\nMIT\r\n","google":"UA-3539093-8","note":"Don't delete this file! It's used internally to help with page regeneration."}
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Crawlcheck by eghuro</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">Crawlcheck</h1>
        <p class="header">Extendable web checker</p>

        <ul>
          <li class="download"><a class="buttons" href="https://github.com/eghuro/crawlcheck/archive/0.04.zip">Download ZIP</a></li>
          <li class="download"><a class="buttons" href="https://github.com/eghuro/crawlcheck/archive/0.04.tar.gz">Download TAR</a></li>
          <li><a class="buttons github" href="https://github.com/eghuro/crawlcheck">View On GitHub</a></li>
          <li><a href="#installation">Install</a></li>
          <li><a href="#configuration">Configure</a></li>
          <li><a href="#running-crawlcheck">Run</a></li>
          <li><a href="#plugins">Extend</a></li>
          <li><a href="#todos">Contribute</a></li>
        </ul>

        <p class="header">This project is maintained by <a class="header name" href="https://github.com/eghuro">eghuro</a></p>


      </header>
      <section>
        <h1>
<a id="crawlcheck" class="anchor" href="#crawlcheck" aria-hidden="true"><span class="octicon octicon-link"></span></a>Crawlcheck</h1>

<p>Crawlcheck is a web crawler invoking plugins on received content. It's intended for verification of websites prior to deployment. The process of verification is customisable by configuration script that allows complex specification which plugins should check particular URIs and content-types.</p>

<p>Current version: 0.04</p>

<h3>Dependencies</h3>
Crawlcheck's engine currently runs on Python 3.5 and uses SQLite3 as a database backend. Crawlcheck uses a number of open source projects to work properly. Python dependencies are listed in <a href="https://github.com/eghuro/crawlcheck/blob/master/requirements.txt">requirements.txt</a>

For a web report there's <a href="https://github.com/eghuro/crawlcheck-report">separate project</a>.

<h3>
<a id="installation" class="anchor" href="#installation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Installation</h3>

<p>
1) Fetch sources</p>

<div class="highlight highlight-sh"><pre> git clone https://github.com/eghuro/crawlcheck crawlcheck</pre></div>

<p>2) Run install script</p>

<div class="highlight highlight-sh"><pre><span class="pl-c1">cd</span> crawlcheck
pip install -r requirements.txt</pre></div>

<p>You will need python 3, python-pip and sqlite3, virtualenv, libmagic, libtidy, libxml2 and libxslt installed. All dev or devel versions.</p>

<h3>
<a id="configuration" class="anchor" href="#configuration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Configuration</h3>

<p>
Configuration file is a Configuration file is a YAML file defined as follows:</p>

<div class="highlight highlight-sh"><pre>---
version: 1.05                   <span class="pl-c"># configuration format version</span>
database: crawlcheck.sqlite     <span class="pl-c"># sqlite database file</span>
maxDepth: 10                    <span class="pl-c"># max amount of links followed from any entry point (default: 0 meaning unlimited)</span>
agent: "Crawlcheck/1.05"        <span class="pl-c"># user agent used (default: Crawlcheck/1.05)</span>
logfile: cc.log                 <span class="pl-c"># where to store logs</span>
maxContentLength: 2000000       <span class="pl-c"># max file size to download</span>
pluginDir: plugin               <span class="pl-c"># where to look for plugins (including subfolders, default: 'plugin')</span>
timeout: 1                      <span class="pl-c"># timeout for networking (default: 1)</span>
cleandb: True                   <span class="pl-c"># clean database before execution</span>
initdb: True                    <span class="pl-c"># initialize database</span>
report: "http://localhost:5000" <span class="pl-c"># report REST API</span>
cleanreport: True               <span class="pl-c"># clean entries in report before sending current</span>
maxVolume: 100000000            <span class="pl-c"># max 100 MB of tmp files (default: sys.maxsize)</span>
maxAttempts: 2                  <span class="pl-c"># attempts to download a web page (default: 3)</span>
dbCacheLimit: 1000000           <span class="pl-c"># cache up to 1M of DB queries</span>
tmpPrefix: "Crawlcheck"         <span class="pl-c"># prefix for temporary file names with downloaded content (default: Crawlcheck)</span>
tmpSuffix: "content"            <span class="pl-c"># suffix for temporary file names with downloaded content (default: content)</span>
tmpDir: "/tmp/"                 <span class="pl-c"># where to store temporary files (default: /tmp/)</span>
dbCacheLimit: 100000            <span class="pl-c"># amount of cached database queries (default: sys.maxsize)</span>
urlLimit: 10000000              <span class="pl-c"># limit on seen URIs</span>
verifyHttps: True               <span class="pl-c"># verify HTTPS? (default: False)</span>
cores: 2                        <span class="pl-c"># amount of cores available (eg. for paralel report payload generation)</span>
recordParams: False             <span class="pl-c"># record request data or URL params? (default: True)</span>
recordHeaders: False            <span class="pl-c"># record response headers? (default: True)</span>
sitemap-file: "sitemap.xml"     <span class="pl-c"># where to store generated sitemap.xml</span>
sitemap-regex: "https?://ksp.mff.cuni.cz(/.*)?" <span class="pl-c"># regex for sitemap generator</span>
yaml-out-file: "cc.yml"         <span class="pl-c"># where to write YAML report</span>
report-file: "report"           <span class="pl-c"># where to write PDF report (.pdf will be added automatically)</span>


<span class="pl-c"># other parameters used by plugins written as ```key: value```</span>

content-types:
 -
   <span class="pl-s"><span class="pl-pds">"</span>content-type<span class="pl-pds">"</span></span>: <span class="pl-s"><span class="pl-pds">"</span>text/html<span class="pl-pds">"</span></span>
   plugins: <span class="pl-c"># plugins to use for given content-type</span>
     - linksFinder
     - tidyHtmlValidator
     - css_scraper
     - formChecker
     - seoimg
     - seometa
     - dupdetect
     - non_semantic_html

 -
   <span class="pl-s"><span class="pl-pds">"</span>content-type<span class="pl-pds">"</span></span>: <span class="pl-s"><span class="pl-pds">"</span>text/css<span class="pl-pds">"</span></span>
   plugins:
     - tinycss
     - dupdetect
 -
   <span class="pl-s"><span class="pl-pds">"</span>content-type<span class="pl-pds">"</span></span>: <span class="pl-s"><span class="pl-pds">"</span>application/gzip<span class="pl-pds">"</span></span>
   plugins:
     - sitemapScanner
 -
   <span class="pl-s"><span class="pl-pds">"</span>content-type<span class="pl-pds">"</span></span>: <span class="pl-s"><span class="pl-pds">"</span>application/xml<span class="pl-pds">"</span></span>
   plugins:
     - sitemapScanner
     - dupdetect

urls:
 -
  url: <span class="pl-s"><span class="pl-pds">"</span>http://mj.ucw.cz/vyuka/.+<span class="pl-pds">"</span></span>
  plugins: <span class="pl-c"># which plugins are allowed for given URL</span>
       - linksFinder
       - tidyHtmlValidator
       - tinycss
       - css_scraper
       - formChecker
       - seoimg
       - seometa
       - dupdeteict
       - non_semantic_html
 -
  url: "http://mj.ucw.cz/" #test links (HEAD request) only
  plugins:

filters: <span class="pl-c"> #Filters (plugins of category header and filter) that can be used</span>
 - depth
 - robots
 - contentLength
 - canonical
 - acceptedType
 - acceptedUri
 - uri_normalizer
 - expectedType

postprocess:
 - sitemap_generator
 - report_exporter
 - yaml_exporter

entryPoints: <span class="pl-c"># where to start</span>
<span class="pl-c"># Note, that once URI get's to the database it's no longer being requested </span>
<span class="pl-c"># (beware of repeated starts, if entry point remains in the database execution won't </span>
<span class="pl-c"># start from this entry point)</span>
 - <span class="pl-s"><span class="pl-pds">"</span>http://mj.ucw.cz/vyuka/<span class="pl-pds">"</span></span></pre></div>

<h3>
<a id="running-crawlcheck" class="anchor" href="#running-crawlcheck" aria-hidden="true"><span class="octicon octicon-link"></span></a>Running crawlcheck</h3>

<p>
Assuming you have gone through set-up and configuration, now run checker:</p>

<div class="highlight highlight-sh"><pre>$ <span class="pl-c1">cd</span> [root]/crawlcheck/src/
$ python checker/ [config.yml]</pre></div>

<p>Note: <code>[root]/crawlcheck</code> is where repository was cloned to, <code>[config.xml]</code> stands for the configuration file path</p>

<h3>
<a id="plugins" class="anchor" href="#plugins" aria-hidden="true"><span class="octicon octicon-link"></span></a>Plugins</h3>

<p>There are currently 5 types of plugins: crawlers, checkers, headers, filters and postprocessors. Crawlers are specializing in discovering new links. Checkers check syntax of various files. Headers check HTTP headers and together with filters serve to customize the crawling process itself. Postprocessors are used to generate reports or other outputs from the application.</p>

<p>Crawlcheck is currently extended with the following plugins:</p>

<ul>
<li>linksFinder (crawler)</li>
<li>sitemapScanner (crawler)</li>
<li>tidyHtmlValidator (checker)</li>
<li>tinycss (checker)</li>
<li>css_scraper (checker)</li>
<li>seoimg (checker)</li>
<li>seometa (checker)</li>
<li>dupdetect (checker)</li>
<li>non_semantic_html (checker)</li>
<li>contentLength (header)</li>
<li>expectedType (header)</li>
<li>canonical (header)</li>
<li>acceptedType (header)</li>
<li>acceptedUri (header)</li>
<li>uri_normalizer (header)</li>
<li>depth (filter)</li>
<li>robots (filter)</li>
<li>report_exporter (postprocessor)</li>
<li>yaml_exporter (postprocessor)</li>
<li>sitemap_generator (postprocessor)</li>
</ul>

<h3>
<a id="how-to-write-a-plugin" class="anchor" href="#how-to-write-a-plugin" aria-hidden="true"><span class="octicon octicon-link"></span></a>How to write a plugin</h3>

<p>Go to <code>crawlcheck/src/checker/plugin/</code>, create <code>my_new_plugin.py</code> and <code>my_new_plugin.yapsy-plugin</code> files there.
Fill out .yapsy-plugin file:</p>

<div class="highlight highlight-sh"><pre>[Core]
Name = Human readable plugin name
Module = my_new_plugin

[Documentation]
Author = Your Name
Version = 0.0
Description = My New Plugin</pre></div>

<p>For plugin itself you need to implement following:</p>

<div class="highlight highlight-sh"><pre>from yapsy.IPlugin import IPlugin
from common import PluginType
from filter import FilterException  # for headers and filters


class MyPlugin(IPlugin):

    category = PluginType.CHECKER <span class="pl-c"># pick appropriate type</span>
    id = myPlugin

    def setJournal(self, journal):
        <span class="pl-c"># record journal somewhere - all categories</span>

    def setQueue(self, queue):
        <span class="pl-c"># record queue somewhere - if needed</span>

    def setConf(self, conf):
        <span class="pl-c"># record configuration - only headers and filters</span>

    def check(self, transaction):
        <span class="pl-c"># implement the checking logic here for crawlers and checkers</span>

    def filter(self, transaction):
        <span class="pl-c"># implement the filtering logic here for filters and headers</span>
        <span class="pl-c"># raise FilterException to filter the transaction out</span>

    def setDb(self, db):
        <span class="pl-c"># record DB somewhere - only postprocessors</span>

    def process(self):
        <span class="pl-c"># implement the postprocessing logic here for postprocessor</span>

<p>See <a href="http://yapsy.sourceforge.net/IPlugin.html">http://yapsy.sourceforge.net/IPlugin.html</a> and <a href="http://yapsy.sourceforge.net/PluginManager.html#plugin-info-file-format">http://yapsy.sourceforge.net/PluginManager.html#plugin-info-file-format</a> for more details.</p>

<h2>
<a id="license" class="anchor" href="#license" aria-hidden="true"><span class="octicon octicon-link"></span></a>License</h2>

<p>MIT</p>
<p>Copyright (c) 2015-2017 Alexandr Mansurov</p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</p>
      </section>
      <footer>
        <p><small>Hosted on <a href="https://pages.github.com">GitHub Pages</a> using the Dinky theme</small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
		          <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-3539093-8");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>
